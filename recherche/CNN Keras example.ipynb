{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> CNN Keras: MNIST Dataset </h1></center>\n",
    "\n",
    "Keras with TensorFlow as backend to calssify digits from the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/conda/lib/python3.7/site-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras) (1.15.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.33.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.19.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.0.9)\n",
      "Requirement already satisfied: mock>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.15.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /opt/conda/lib/python3.7/site-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import Dense, Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "K.set_image_data_format('channels_last')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./data/cnn/train.csv')\n",
    "test = pd.read_csv('./data/cnn/test.csv')\n",
    "\n",
    "y = X[\"label\"]\n",
    "X.drop([\"label\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.2 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 28, 28, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Eploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of training examples = 33600\n",
      "the number of classes = 10\n",
      "Dimention of images = 28 x 28  \n",
      "The number of occuranc of each class in the dataset = {0: 3316, 1: 3775, 2: 3331, 3: 3414, 4: 3233, 5: 3093, 6: 3352, 7: 3508, 8: 3228, 9: 3350}  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"the number of training examples = %i\" % X_train.shape[0])\n",
    "print(\"the number of classes = %i\" % len(numpy.unique(y_train)))\n",
    "print(\"Dimention of images = {:d} x {:d}  \".format(X_train[1].shape[0],X_train[1].shape[1])  )\n",
    "\n",
    "#This line will allow us to know the number of occurrences of each specific class in the data\n",
    "unique, count= numpy.unique(y_train, return_counts=True)\n",
    "print(\"The number of occuranc of each class in the dataset = %s \" % dict (zip(unique, count) ), \"\\n\" )\n",
    " \n",
    "images_and_labels = list(zip(X_train,  y_train))\n",
    "for index, (image, label) in enumerate(images_and_labels[:12]):\n",
    "    plt.subplot(5, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.squeeze(), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('label: %i' % label )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design and Achitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model.add(Conv2D(40, kernel_size=5, padding=\"same\",input_shape=(28, 28, 1), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(70, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(Conv2D(500, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(1024, kernel_size=3, padding=\"valid\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Activation\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train).astype('int32')\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/12\n",
      "1050/1050 [==============================] - 375s 357ms/step - loss: 0.3778 - acc: 0.8805\n",
      "Epoch 2/12\n",
      "1050/1050 [==============================] - 372s 354ms/step - loss: 0.1197 - acc: 0.9688\n",
      "Epoch 3/12\n",
      "1050/1050 [==============================] - 372s 355ms/step - loss: 0.0993 - acc: 0.9750\n",
      "Epoch 4/12\n",
      "1050/1050 [==============================] - 373s 355ms/step - loss: 0.0882 - acc: 0.9793\n",
      "Epoch 5/12\n",
      "1050/1050 [==============================] - 377s 359ms/step - loss: 0.0752 - acc: 0.9813\n",
      "Epoch 6/12\n",
      "1050/1050 [==============================] - 376s 358ms/step - loss: 0.0710 - acc: 0.9833\n",
      "Epoch 7/12\n",
      "1050/1050 [==============================] - 374s 356ms/step - loss: 0.0685 - acc: 0.9844\n",
      "Epoch 8/12\n",
      "1050/1050 [==============================] - 373s 355ms/step - loss: 0.0571 - acc: 0.9867\n",
      "Epoch 9/12\n",
      "1050/1050 [==============================] - 373s 356ms/step - loss: 0.0684 - acc: 0.9853\n",
      "Epoch 10/12\n",
      "1050/1050 [==============================] - 375s 357ms/step - loss: 0.0593 - acc: 0.9869\n",
      "Epoch 11/12\n",
      "1050/1050 [==============================] - 375s 357ms/step - loss: 0.0611 - acc: 0.9864\n",
      "Epoch 12/12\n",
      "1050/1050 [==============================] - 373s 356ms/step - loss: 0.0531 - acc: 0.9878\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_test = X_test.reshape(-1,28,28,1)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "X_train2 = numpy.array(X_train, copy=True) \n",
    "y_train2 = numpy.array(y_train, copy=True) \n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    )\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "print(type(X_train2))\n",
    "print(type(X_train))\n",
    "\n",
    "# Concatenating the old data with the augmented data\n",
    "result_x  = numpy.concatenate((X_train, X_train2), axis=0)\n",
    "result_y  = numpy.concatenate((y_train, y_train2), axis=0)\n",
    "\n",
    "\n",
    "# # fits the model on batches with real-time data augmentation:\n",
    "history = model.fit_generator(datagen.flow(result_x, result_y, batch_size=35),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15181639777766773, 0.9901190476190476]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose = 10 )\n",
    "print ( scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = (test.values).reshape(-1, 28, 28 , 1).astype('float32')\n",
    "\n",
    "res = model.predict(test_set)\n",
    "res = numpy.argmax(res,axis = 1)\n",
    "res = pd.Series(res, name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1 ,28001) ,name = \"ImageId\"),   res],axis = 1)\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
